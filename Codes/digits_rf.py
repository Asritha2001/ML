# -*- coding: utf-8 -*-
"""digits_RF.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1RvFNNJkJkd0ceZBgqSYHCUo-PrOwjPjg
"""

import pandas as pd
import numpy as np
from math import log2
from math import sqrt
from collections import Counter
import matplotlib.pyplot as plt
import random
from sklearn import datasets
from sklearn.metrics import accuracy_score, f1_score


# data = pd.read_csv("hw3_house_votes_84.csv", skiprows = 1, header=None)
# data = data.dropna()
# data = pd.read_csv("hw3_wine.csv", skiprows = 1, header=None, sep='\t')
digits = datasets.load_digits()
df = pd.DataFrame(digits.data, columns=digits.feature_names)
df['target'] = digits.target
# print(df.head())

# print(digits)

# first find the best attribute from all the features present
# divide the data into branches of the best feature
# find best among the remaining features
class Node:
  def __init__(self, index_of_attribute=None, cutting_Point=None, left=None, right=None, leaf_label=None):
    self.index_of_attribute = index_of_attribute
    self.cutting_Point = cutting_Point
    self.left = left
    self.right = right
    self.leaf_label = leaf_label

class DecisionTree:
  def __init__(self, min_samples = 2, depth_max = 2): #Initiating the DecisionTree class
    self.root = None
    self.min_samples = min_samples
    self.depth_max = depth_max

  def constructTree(self, data, depth=0):
    num_samples = len(data)
    num_attributes = len(data[0])-1
    m = int(sqrt(num_attributes))
    labels = np.unique(data[:,-1])
    all_attributes = list(i for i in range(num_attributes))
    #Checking the stopping criteria
    if num_samples>=self.min_samples and depth<=self.depth_max and len(labels) > 1:
      attributes = random.sample(all_attributes, m)
      if self.best_criteria(data, attributes):
        index_of_attribute,cutting_Point = self.best_criteria(data, attributes)
        data_left = np.array([row for row in data if row[index_of_attribute]<=cutting_Point])
        data_right = np.array([row for row in data if row[index_of_attribute]>cutting_Point])
        # recursive step
        l_tree = self.constructTree(data_left, depth+1)
        r_tree = self.constructTree(data_right, depth+1)
        return Node(index_of_attribute, cutting_Point, l_tree, r_tree)

    #If it reaches stopping criteria it assigns it to the leaf node
    d = {}
    for l in labels:
      d[l] = 0
    for i in range(len(data)):
      d[data[:,-1][i]] += 1
    label = max(d, key=d.get)
    return Node(leaf_label = label)

  def best_criteria(self, data, num_attributes):
    max_gain = -1
    best_att_index = -1
    best_cutting_point = -1
    infoGain = -1
    ginivalue = 1
    min_gini = 1
    for attribute_index in num_attributes:
      attribute_values = data[:, attribute_index]
      possible_cuttingPoints = np.unique(attribute_values)#categorical columns
      # cuttingPoint = np.mean(attribute_values) # numerical columns
      #Runs through all possible unique points in the attribute to find cutting point
      for cuttingPoint in possible_cuttingPoints:
      # for i in range(1):
        data_left = np.array([row for row in data if row[attribute_index]<=cuttingPoint])
        data_right = np.array([row for row in data if row[attribute_index]>cuttingPoint])
        if len(data_left)>0 and len(data_right)>0:
          y, left_y, right_y = data[:, -1], data_left[:, -1], data_right[:, -1]
          infoGain = informationGain(y, left_y, right_y)
          #gini_value = gini(y, left_y, right_y)
          # It decides the best split if the information gain is maximum
          if infoGain>max_gain:
            max_gain = infoGain
            best_att_index = attribute_index
            best_cutting_point = cuttingPoint
          # if gini_value<min_gini:
          #   min_gini = gini_value
          #   best_att_index = attribute_index
          #   best_cutting_point = cuttingPoint
    if infoGain>0:
    #if min_gini<1:
      return best_att_index,best_cutting_point

  def fit(self, X, Y):
    #Building the decision tree and assigning it to the root
    self.root = self.constructTree(np.concatenate((X, Y), axis=1))

  def countPredictions(self, X, Y):
    #Count the successful predictions
    predictions = 0
    for i in range(len(X)):
      if self.predict(X[i],self.root) == Y[i]:
        predictions +=1
    return predictions

  def predict(self, x, node):
    # Traverse through the tree and if it reaches the leaf node, then it returns it
    if node.leaf_label != None:
      return node.leaf_label
    attribute_val = x[node.index_of_attribute]
    if attribute_val<=node.cutting_Point:
      return self.predict(x, node.left)
    else:
      return self.predict(x, node.right)

class RandomForest:
  def __init__(self, n_trees, min_samples = 2, depth_max = 2):
    self.n_trees = n_trees
    self.min_samples = min_samples
    self.depth_max = depth_max
    self.trees = []

  def bootstrap(self,X,y):
    l = len(X)
    indices = np.random.choice(l,l,replace=True)
    return X[indices],y[indices]

  def fit(self, X, y):
    self.trees = []
    for _ in range(self.n_trees):
      tree = DecisionTree(min_samples=self.min_samples, depth_max=self.depth_max)
      X_sample, y_sample = self.bootstrap(X,y)
      tree.fit(X_sample, y_sample)
      self.trees.append(tree)

  def predict(self, X):
    pred_tree = np.array([tree.predict(X[i],tree.root) for i in range(len(X)) for tree in self.trees])
    pred_tree = pred_tree.reshape(-1, self.n_trees).T
    return np.array([Counter(col).most_common(1)[0][0] for col in pred_tree.T])


def informationGain(node, left, right):
  info_gain = entropy_cal(node) - ((len(left)*entropy_cal(left) + len(right)*entropy_cal(right)) / len(node))
  return info_gain

def gini(node, left, right):
  gi = gini_cal(node) - ((len(left)*gini_cal(left) + len(right)*gini_cal(right)) / len(node))
  return gi

def entropy_cal(data_list):
  data_list = list(data_list)
  prob_list = []
  c = Counter(data_list)
  for i in c:
    prob_list.append(data_list.count(i)/len(data_list))
  entropy = sum([-p * log2(p) for p in prob_list if p>0])
  return entropy

def gini_cal(data_list):
  data_list = list(data_list)
  prob_square_list = []
  c = Counter(data_list)
  for i in c:
    prob_square_list.append((data_list.count(i)/len(data_list))**2)
  return (1 - sum(prob_square_list))

def stratification(data,kfolds):
  X = data.iloc[:,0:-1].values
  y = data.iloc[:,-1].values.reshape(-1,1)
  total_instances = len(y)
  # dividing indices into seperate unique lists
  c1 = []
  c2 = []
  class_splits = []
  for i in range(total_instances):
    if y[i] == 0:
      c1.append(i)
    else:
      c2.append(i)
  classes = [c1,c2]
  # randomizing the class indices and splitting it
  for cl in classes:
    np.random.shuffle(cl)
    class_splits.append(np.array_split(cl, kfolds))
  # forming data into folds
  splits = []
  for fold in range(kfolds):
      test_indices = np.concatenate([class_splits[class_idx][fold] for class_idx in range(2)])
      train_indices = np.concatenate([np.concatenate(class_splits[class_idx][:fold] + class_splits[class_idx][fold + 1:]) for class_idx in range(2)])
      splits.append((train_indices, test_indices))
  return splits,X,y


def calculate_precision_recall_confusion_matrix(y_true, y_pred):
  confusion_matrix = [[0,0],[0,0]]
  for i in range(len(y_true)):
    confusion_matrix[y_true[i][0]][y_pred[i]] += 1
  # print(confusion_matrix)
  TP = confusion_matrix[1][1]
  TN = confusion_matrix[0][0]
  FN = confusion_matrix[1][0]
  FP = confusion_matrix[0][1]
  accuracy = (TP + TN)/(TP + TN + FP + FN)
  precision = TP/(TP + FP) if (TP + FP)!=0 else 0
  recall = TP/(TP + FN)
  f1_score = (2 * precision * recall) / (precision + recall) if (precision + recall)!=0 else 0
  return accuracy, precision, recall, f1_score


def evaluate_classifier(data, ntrees):
  splits,X,y = stratification(data, kfolds=10)
  metrics = []
  for ntree in ntrees:
    accuracy, f1 = [], []
    for train_index, test_index in splits:
      X_train, X_test = X[train_index], X[test_index]
      y_train, y_test = y[train_index], y[test_index]
      rf = RandomForest(n_trees=ntree, min_samples=3, depth_max=6)
      rf.fit(X_train, y_train)
      y_pred = rf.predict(X_test)
      test_acc = accuracy_score(y_test, y_pred)
      test_f1 = f1_score(y_test, y_pred,average='macro')
      # accuracy_score, precision_score, recall_score, f1_score = calculate_precision_recall_confusion_matrix(y_test, y_pred)
      accuracy.append(test_acc)
      f1.append(test_f1)
    metrics.append((np.mean(accuracy), np.mean(f1)))
  return metrics

def plot_metrics(metrics, ntrees):
  plt.plot(ntrees, [m[0] for m in metrics], marker='o')
  plt.xticks(ntrees)
  plt.xlabel('Number of trees')
  plt.ylabel('Accuracy on the test set')
  plt.title('Accuracy vs ntree')
  plt.show()

  plt.plot(ntrees, [m[1] for m in metrics], marker='o')
  plt.xticks(ntrees)
  plt.xlabel('Number of trees')
  plt.ylabel('F1 on the test set')
  plt.title('F1 vs ntree')
  plt.show()

ntrees = [1,5,10,20,30,40,50]
digits_metrics = evaluate_classifier(df, ntrees)

# Plot the metrics
plot_metrics(digits_metrics, ntrees)

# Analyze the results
for i, ntree in enumerate(ntrees):
  print(f'For ntree={ntree}:')
  print(f'  Accuracy: {digits_metrics[i][0]:.4f}')
  print(f'  F1 Score: {digits_metrics[i][1]:.4f}')